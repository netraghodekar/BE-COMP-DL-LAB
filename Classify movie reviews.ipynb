{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN/hFplLlIK1lASJMx94ysl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":30,"metadata":{"id":"8sxG6I6hBTxx","executionInfo":{"status":"ok","timestamp":1676952151289,"user_tz":-330,"elapsed":8046,"user":{"displayName":"net g","userId":"07248674673512778691"}}},"outputs":[],"source":["from keras.datasets import imdb\n","\n","# Load the data, keeping only 10,000 of the most frequently occuring words\n","(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = 10000)"]},{"cell_type":"code","source":["# Since we restricted ourselves to the top 10000 frequent words, no word index should exceed 10000\n","# we'll verify this below\n","\n","# Here is a list of maximum indexes in every review --- we search the maximum index in this list of max indexes\n","print(type([max(sequence) for sequence in train_data]))\n","\n","# Find the maximum of all max indexes\n","max([max(sequence) for sequence in train_data])"],"metadata":{"id":"QaSlNoJZBabP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's quickly decode a review\n","\n","# step 1: load the dictionary mappings from word to integer index\n","word_index = imdb.get_word_index()\n","\n","# step 2: reverse word index to map integer indexes to their respective words\n","reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n","\n","# Step 3: decode the review, mapping integer indices to words\n","#\n","# indices are off by 3 because 0, 1, and 2 are reserverd indices for \"padding\", \"Start of sequence\" and \"unknown\"\n","decoded_review = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[0]])\n","\n","decoded_review"],"metadata":{"id":"F-K8ka2GB879"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(reverse_word_index)"],"metadata":{"id":"g_IwW9LiCDBN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","def vectorize_sequences(sequences, dimension=10000):\n","    results = np.zeros((len(sequences), dimension))    # Creates an all zero matrix of shape (len(sequences),10K)\n","    for i,sequence in enumerate(sequences):\n","        results[i,sequence] = 1                        # Sets specific indices of results[i] to 1s\n","    return results\n","\n","# Vectorize training Data\n","X_train = vectorize_sequences(train_data)\n","\n","# Vectorize testing Data\n","X_test = vectorize_sequences(test_data)"],"metadata":{"id":"f2eX58pKCGet"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train[0]"],"metadata":{"id":"AxsYkqvzCKCt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.shape"],"metadata":{"id":"hVaIp8n6CNs9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train = np.asarray(train_labels).astype('float32')\n","y_test  = np.asarray(test_labels).astype('float32')"],"metadata":{"id":"Hgnvt8EvCRfc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras import models\n","from keras import layers\n","\n","model = models.Sequential()\n","model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n","model.add(layers.Dense(16, activation='relu'))\n","model.add(layers.Dense(1, activation='sigmoid'))\n"],"metadata":{"id":"Jbf0-FzwCT6N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras import optimizers\n","from keras import losses\n","from keras import metrics\n","\n","model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n","              loss = losses.binary_crossentropy,\n","              metrics = [metrics.binary_accuracy])\n"],"metadata":{"id":"5lnHIoBkCZ4d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Input for Validation\n","X_val = X_train[:10000]\n","partial_X_train = X_train[10000:]\n","\n","# Labels for validation\n","y_val = y_train[:10000]\n","partial_y_train = y_train[10000:]\n"],"metadata":{"id":"1bKdpemgCeP9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(partial_X_train,\n","                   partial_y_train,\n","                   epochs=20,\n","                   batch_size=512,\n","                   validation_data=(X_val, y_val))"],"metadata":{"id":"6hVinnynCkx8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history_dict = history.history\n","history_dict.keys()\n"],"metadata":{"id":"2605x2zeCqBc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","%matplotlib inline"],"metadata":{"id":"fP_W_v3xDTgW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plotting losses\n","loss_values = history_dict['loss']\n","val_loss_values = history_dict['val_loss']\n","\n","epochs = range(1, len(loss_values) + 1)\n","\n","plt.plot(epochs, loss_values, 'bo', label=\"Training Loss\")\n","plt.plot(epochs, val_loss_values, 'b', label=\"Validation Loss\")\n","\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss Value')\n","plt.legend()\n","\n","plt.show()"],"metadata":{"id":"DJMY1yQzDWor"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training and Validation Accuracy\n","\n","acc_values = history_dict['binary_accuracy']\n","val_acc_values = history_dict['val_binary_accuracy']\n","\n","epochs = range(1, len(loss_values) + 1)\n","\n","plt.plot(epochs, acc_values, 'ro', label=\"Training Accuracy\")\n","plt.plot(epochs, val_acc_values, 'r', label=\"Validation Accuracy\")\n","\n","plt.title('Training and Validation Accuraccy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.show()\n"],"metadata":{"id":"UGbU80FsDf5M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.fit(partial_X_train,\n","                   partial_y_train,\n","                   epochs=3,\n","                   batch_size=512,\n","                   validation_data=(X_val, y_val))"],"metadata":{"id":"mOWLy9HBDmEb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Making Predictions for testing data\n","np.set_printoptions(suppress=True)\n","result = model.predict(X_test)\n","result"],"metadata":{"id":"17OdkAb8DpPL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import mean_absolute_error\n","y_pred = np.zeros(len(result))\n","for i, score in enumerate(result):\n","    y_pred[i] = score\n","mae = mean_absolute_error(y_pred, y_test)\n","# Error\n","mae\n"],"metadata":{"id":"3bX2b-XrDwza"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip3 install ann_visualizer"],"metadata":{"id":"7G1I3ckEE65D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from ann_visualizer.visualize import ann_viz \n","ann_viz(model, title=\"Binary Classification of Movie Reviews\", filename=\"imdb_review.gv\")"],"metadata":{"id":"Bi0bos6TD3e6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8ldd0JxaI054"},"execution_count":null,"outputs":[]}]}